
<!doctype html>
<html>

  <head>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
    <!--     Get up-to-date fontawesome config -->
    <script src="https://use.fontawesome.com/115eb0f096.js"></script>
    <script>
     	function showhide(id) {
    	var e = document.getElementById(id);
    	e.style.display = (e.style.display == 'block') ? 'none' : 'block';
 		}
    </script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Yicong Chen's Homepage</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <!--     For academic icon such as google scholar -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <!--link rel="icon" type="image/x-icon" href="favicon.ico?"-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,500,600,700" rel="stylesheet">
    
    <!--if lt IE 9>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <!endif-->
   
    
  </head>

  <body>
    <div class="wrapper">
      <header>

        <img border=0 Vspace=5 Hspace=0
        src="images/me.JPG"
        alt="Yicong"
        width="221" height="289">
        <br><br>

        <p>
          <par><font size=3px>Bryce Yicong Chen (陈翊聪)</font></par><br>
          Incoming PhD student<br>
          University of Washington<br>
          <code>Email: bychen AT uw.edu</code><br>
          <code>LinkedIn: <a href="https://www.linkedin.com/in/yicong-chen-046993250/", target="_blank">Yicong Chen</a></code><br>
          <code>CV: <a href="https://bryce-chen.github.io/pdfs/CV.pdf", target="_blank">here</a> </code>
        </p>
      </header>

      <section>
      <h1>About Me</h1>

      I am an incoming PhD student at the <a href="https://www.washington.edu/">University of Washington</a>, where I will be advised by Prof. <a href="https://people.ece.uw.edu/ostendorf/">Mari Ostendorf</a>. 
      My research will focus on natural language processing (NLP). 
      Prior to this, I graduated from the <a href="https://www.wisc.edu/">University of Wisconsin-Madison</a> with a B.S. in Computer Engineering and Computer Science, 
      where I had the privilege of being advised by Prof. <a href="https://kangwooklee.com/aboutme/">Kangwook Lee</a>.
        
      <br>

      <h2 id="Pubs">Publications</h2>
      <a href="https://arxiv.org/abs/2402.01293", target="_blank">Can MLLMs Perform Text-to-Image In-Context Learning?</a>
        </a><br>
        Yuchen Zeng*, Wonjun Kang*, <b>Yicong Chen</b>, Hyung Il Koo, Kangwook Lee<br>
        <i>Under review</i>
        <!-- <br><span style="font-size: smaller;">
        &#x2022; <b>Summary</b>: We introduce a buffer-based Gradient Projection method for Continual Federated Learning that combats catastrophic forgetting using local buffer samples and aggregated buffer gradients.
        <br><br></span> -->
        <br><br>
      
      <a href="https://bryce-chen.github.io/pdfs/FedGP_Buffer_based_Gradient_Projection_for_Continual_Federated_Learning.pdf", target="_blank">FedGP: Buffer-based Gradient Projection for Continual Federated Learning</a>
        </a><br>
        Shenghong Dai, <b>Yicong Chen</b>, Jy-yong Sohn, S M Iftekharul Alam, Ravikumar Balakrishnan, Suman Banerjee, Nageen Himayat, Kangwook Lee<br>
        <i>Federated Learning Systems (FLSys) Workshop @ MLSys 2023 &#x2022; Oral Presentation &#x2022; Best Paper Award</i>
        <!-- <br><span style="font-size: smaller;">
        &#x2022; <b>Summary</b>: We introduce a buffer-based Gradient Projection method for Continual Federated Learning that combats catastrophic forgetting using local buffer samples and aggregated buffer gradients.
        <br><br></span> -->
        <br><br>

        <a href="https://bryce-chen.github.io/pdfs/Zero-shot_Improvement_of_Object_Counting_with_CLIP.pdf", target="_blank">Zero-shot Improvement of Object Counting with CLIP</a>
        </a><br>
        Ruisu Zhang*, <b>Yicong Chen*</b>, Kangwook Lee<br>
        <i>Robustness of Few-shot and Zero-shot Learning in Foundation Models (R0-FoMo) Workshop @ NeurIPS 2023</i>
        <!-- <br><span style="font-size: smaller;">
        &#x2022; <b>Summary</b>: We mitigate CLIP's object counting limitations by introducing a zero-shot method that manipulates its text embedding space, enhancing counting accuracy and also improving the performance of text-to-image generative models.
        <br><br></span> -->
        <br><br>

        <a href="https://bryce-chen.github.io/pdfs/Coded_Prompts_for_Large_Language_Models.pdf", target="_blank">Coded Prompts for Large Language Models</a>
        </a><br>
        Ziqian Lin, <b>Yicong Chen</b>, Yuchen Zeng, Kangwook Lee<br>
        <i>Robustness of Few-shot and Zero-shot Learning in Foundation Models (R0-FoMo) Workshop @ NeurIPS 2023</i>
        <!-- <br><span style="font-size: smaller;">
        &#x2022; <b>Summary</b>: We introduce coded prompts, inspired by coding theory, to process multiple inputs simultaneously in Large Language Models (LLMs), enhancing task performance. Viewing LLM inference as a noisy communication channel, a coded prompt has the potential to protect against information lost.
        <br><br></span> -->
        <br><br>

      </tbody></table>

      </section>

      <footer>
          <p><span style="font-size:0.7em">Based on <a href="https://github.com/orderedlist/minimal" style="color:black">minimal</a> by <a href="https://github.com/orderedlist" style="color:black">orderedlist</a>&mdash;<a href="http://creativecommons.org/licenses/by-sa/3.0/" style="color:black">CC BY-SA 3.0</a></span></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>

 </html>

